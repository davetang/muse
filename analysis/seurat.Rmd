---
title: "Getting started with Seurat"
date: "`r Sys.Date()`"
output:
  workflowr::wflow_html:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# https://stackoverflow.com/questions/30237310/setting-work-directory-in-knitr-using-opts-chunksetroot-dir-doesnt-wor
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

This post follows the Peripheral Blood Mononuclear Cells (PBMCs) [tutorial](https://satijalab.org/seurat/articles/pbmc3k_tutorial) for 2,700 single cells. It was written while I was going through the tutorial and contains my notes. The dataset for this tutorial can be downloaded from the [10X Genomics dataset page](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k) but it is also hosted on Amazon (see below). The PBMCs, which are primary cells with relatively small amounts of RNA (around 1pg RNA/cell), come from a healthy donor. There were 2,700 cells detected and sequencing was performed on an Illumina NextSeq 500 with around 69,000 reads per cell. To get started [install Seurat](https://satijalab.org/seurat/articles/install.html) by using install.packages() and the [presto](https://github.com/immunogenomics/presto) package, which will be used finding markers. (The [bench](https://github.com/r-lib/bench) package is also installed for timing some steps.)

```{r install_seurat, eval=FALSE}
install.packages("Seurat")
remotes::install_github("immunogenomics/presto")
install.packages("bench")
```

If you get the warning:

>‘SeuratObject’ was built under R 4.3.0 but the current version is 4.3.2; it is recomended that you
reinstall ‘SeuratObject’ as the ABI (sic) for R may have changed

re-install the `SeuratObject` package using a repository that has an updated copy. The same goes for the `htmltools` package.

```{r install_seurat_obj, eval=FALSE}
install.packages("SeuratObject", repos = "https://cloud.r-project.org/")
install.packages("htmltools", repos = "https://cloud.r-project.org/")
packageVersion("SeuratObject")
packageVersion("htmltools")
```

Load `Seurat` and `bench` for some benchmarking.

```{r load_seurat}
suppressPackageStartupMessages(library("Seurat"))
suppressPackageStartupMessages(library("bench"))
suppressPackageStartupMessages(library("presto"))
packageVersion("Seurat")
packageVersion('presto')
```

## Data

To follow the tutorial, you'll need the 10X data, which can be download from AWS.

```{bash, eval=FALSE}
mkdir -p data/pbmc3k && cd data/pbmc3k
wget -c https://s3-us-west-2.amazonaws.com/10x.files/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz
tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz
```

The extracted files.

```{bash}
ls -1 data/pbmc3k/filtered_gene_bc_matrices/hg19
```

`matrix.mtx` is a [MatrixMarket](https://math.nist.gov/MatrixMarket/formats.html) file. It has the following properties:

* Only non-zero entries are stored in the file
* Comments start with a `%`, like LaTeX
* The first line indicates the total number of rows, columns, and entries
* The following lines after the first provide a row and column number and the value at that coordinate

```{bash}
head data/pbmc3k/filtered_gene_bc_matrices/hg19/matrix.mtx
```

## Seurat object

Load 10x data into a matrix using `Read10X()`; we will use `bench::mark()` to measure memory usage and to time how long the function ran. Note that using `bench::mark()` will mean that the expression will run at least twice.

```{r read_10x}
bench::mark(
  pbmc.data <- Read10X(data.dir = "data/pbmc3k/filtered_gene_bc_matrices/hg19/")
)
```

The matrix is in the [dgCMatrix-class](https://stat.ethz.ch/R-manual/R-patched/library/Matrix/html/dgCMatrix-class.html):

> The dgCMatrix class is a class of sparse numeric matrices in the compressed, sparse, column-oriented format. In this implementation the non-zero elements in the columns are sorted into increasing row order. dgCMatrix is the “standard” class for sparse numeric matrices in the Matrix package. 

```{r dg_c_matrix_class}
class(pbmc.data)
```

The matrix (gene by barcode) contains `r nrow(pbmc.data)` rows (genes) and `r ncol(pbmc.data)` columns (barcodes).

```{r dim_pbmc_data}
dim(pbmc.data)
```

Save as CSV file.

```{r write_csv}
system.time(
  write.csv(x = pbmc.data, file = "data/pbmc3k.csv")
)
```

Gzip.

```{bash}
if [[ ! -f data/pbmc3k.csv.gz ]]; then
   gzip data/pbmc3k.csv
fi
ls -lh data/pbmc3k.csv.gz
```

Check out the first six genes and barcodes.

```{r glimpse_pbmc_data}
pbmc.data[1:6, 1:6]
```

Summary of total expression (number of detected transcripts) per single barcode.

```{r total_expression_per_bc}
summary(colSums(pbmc.data))
```

Summary of total number of transcripts per gene.

```{r total_expression_per_gene}
summary(colSums(t(pbmc.data)))
```

The range in the total expression of genes is quite large. A more useful summary is how often a gene is detected (at least one transcript) across all barcodes.

```{r at_least_one_transcript}
at_least_one <- apply(pbmc.data, 2, function(x) sum(x>0))
```

On average (median), a gene is detected in `r median(at_least_one)` barcodes (out of `r ncol(pbmc.data)`). This is a more useful metric for filtering out genes instead of relying on total expression.

```{r at_least_one_transcript_dist}
hist(
  at_least_one,
  breaks = 100,
  main = "Distribution of detected genes",
  xlab = "Genes with at least one tag"
)
abline(v = median(at_least_one), col = 2, lty = 3)
```

Total expression per cell. The median sum of expression among the single cells is `r median(colSums(pbmc.data))`. This distribution is very similar to the distribution of detected genes shown above.

```{r expression_sum_per_cell_dist}
hist(
  colSums(pbmc.data),
  breaks = 100,
  main = "Expression sum per cell",
  xlab = "Sum expression"
)
abline(v = median(colSums(pbmc.data)), col = 2, lty = 3)
```

We will filter out genes and barcodes before we continue with the analysis. The tutorial has arbitrary values of keeping genes expressed in three or more cells and keeping barcodes with at least 200 detected genes.

Manually check the number of genes detected in three or more cells; a lot of genes are not detected in 3 or more cells.

```{r manual_check_genes_filter}
tmp <- apply(pbmc.data, 1, function(x) sum(x>0))
table(tmp>=3)
```

All cells have at least 200 detected genes (where detected is at least one transcript).

```{r manual_check_at_least_one}
keep <- tmp>=3
tmp <- pbmc.data[keep,]
at_least_one <- apply(tmp, 2, function(x) sum(x>0))
summary(at_least_one)
```

We will now create the Seurat object using `CreateSeuratObject`; see `?SeuratObject` for more information on the class.

```{r create_seurat_object}
pbmc <- CreateSeuratObject(
  counts = pbmc.data,
  min.cells = 3,
  min.features = 200,
  project = "pbmc3k"
)

class(pbmc)
```

The Seurat object contains the same number of genes and barcodes as our manual checks above. 

```{r check_out_seurat_obj}
pbmc
```

Slots in Seurat object.

> SeuratObject: Data Structures for Single Cell Data
>
> Defines S4 classes for single-cell genomic data and associated information, such as dimensionality reduction embeddings, nearest-neighbor graphs, and spatially-resolved coordinates. Provides data access methods and R-native hooks to ensure the Seurat object is familiar to other R users

Read more about the [S4 class](https://adv-r.hadley.nz/s4.html) in the Advanced R book.

```{r seurat_obj_slot_names}
slotNames(pbmc)
```

## Basic filtering

The tutorial states that "The number of genes and UMIs (nGene and nUMI) are automatically calculated for every object by Seurat." The nUMI is calculated as `num.mol <- colSums(object.raw.data)`, i.e. each transcript is a unique molecule. The number of genes is simply the tally of genes with at least 1 transcript; `num.genes <- colSums(object.raw.data > is.expr`) where `is.expr` is zero.

A common quality control metric is the percentage of transcripts from the mitochondrial genome. According to the paper [Classification of low quality cells from single-cell RNA-seq data](https://pubmed.ncbi.nlm.nih.gov/26887813/) the reason this is a quality control metric is because if a single cell is lysed, cytoplasmic RNA will be lost apart from the RNA that is enclosed in the mitochondria, which will be retained and sequenced.

Human mitochondria genes conveniently start with MT; however, we can generalise this a little (for use with other organisms) by ignoring case.

```{r mito_genes}
mito.genes <- grep(pattern = "^MT-", x = rownames(x = pbmc@assays$RNA), ignore.case = TRUE, value = TRUE)
length(mito.genes)
```

Manually calculate the mitochrondrial percent for each barcode.

```{r manual_percent_mito}
percent.mito <- Matrix::colSums(pbmc[['RNA']]$counts[mito.genes, ]) / Matrix::colSums(pbmc[['RNA']]$counts) * 100
head(percent.mito)
```

Metadata is stored in the `meta.data` slot.

```{r meta_data_slot}
head(pbmc@meta.data)
```

Add mitochondrial percent to the meta using `AddMetaData`.

```{r add_percent_mito}
pbmc <- AddMetaData(
  object = pbmc,
  metadata = percent.mito,
  col.name = "percent.mito"
)
head(pbmc@meta.data)
```

Use `PercentageFeatureSet` to calculate the percentage of a set of features, which saves us from some typing. The `[[` operator can add columns to object metadata, which is a great place to stash QC stats.

```{r percentage_feature_set_mito}
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")
head(pbmc@meta.data[, c('percent.mito', 'percent.mt')])
```

Instead of setting a hard filtering threshold, one can use the 3 * [Median Absolute Deviation](https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#filtering-low-quality-reads) to determine threshold limits for filtering out cells.

```{r mad_percent_mito}
median(pbmc@meta.data$percent.mt) - 3 * mad(pbmc@meta.data$percent.mt)
median(pbmc@meta.data$percent.mt) + 3 * mad(pbmc@meta.data$percent.mt)
```

Plot number of genes, UMIs, and percent mitochondria, which are typical QC metrics, as a violin plot using `VlnPlot()`.

```{r vln_plot_qc}
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
```

A couple of cells have high mitochondrial percentage which may indicate lost of cytoplasmic RNA.

`FeatureScatter()` is typically used to visualise feature-feature relationships, but can be used
for anything calculated by the object, i.e. columns in object metadata, PC scores etc.

```{r feature_scatter_qc}
plot1 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + plot2
```

Additional sanity checks; I already know all cells have >200 genes.

```{r percent_mito_nfeat_check}
table(pbmc@meta.data$percent.mito < 5 & pbmc@meta.data$nFeature_RNA<2500)
```

62 barcodes will be filtered out.

```{r subset_seurat_obj}
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)
pbmc
```

## Normalisation

After removing unwanted cells from the dataset, the next step is to normalise the data, so that barcodes can be compared against each other. At the time of writing (2017), the only normalisation method implemented in Seurat was log normalisation.

```{r total_exp_before_lognorm}
hist(
  colSums(pbmc[['RNA']]$counts),
  breaks = 100,
  main = "Total expression before normalisation",
  xlab = "Sum of expression"
)
```

The global-scaling normalisation method known as "LogNormalize" normalises the feature expression measurements for each barcode by its total expression, multiplies this value by a scale factor (10,000 by default), and finally log-transforms the result. In Seurat v5, normalised values are stored in the data layer, i.e., `pbmc[["RNA"]]$data`.

Manually perform log-normalisation as I interpret it above.

```{r manual_normalisation}
raw_counts <- as.matrix(pbmc[['RNA']]$counts)
norm_counts <- apply(raw_counts, 2, function(x) x / sum(x) * 10000)
norm_counts <- log1p(norm_counts)
dim(norm_counts)
```

For clarity, in this previous line of code (and in future commands), we provide the default values for certain parameters in the function call. However, this isn’t required and the same behavior can be achieved with:

```{r normalise_data}
# the code below is the same as
# pbmc <- NormalizeData(pbmc)
# since the two arguments are the default
pbmc <- NormalizeData(pbmc, normalization.method = "LogNormalize", scale.factor = 10000, verbose = FALSE)
pbmc
```

Compare `NormalizeData` results with results from my implementation.

```{r norm_counts_seurat}
norm_counts_seurat <- as.matrix(pbmc[['RNA']]$data)
identical(norm_counts_seurat, norm_counts)
```

While this method of normalisation is standard and widely used in scRNA-seq analysis, global-scaling relies on an assumption that **each cell originally contains the same number of RNA molecules**. Alternative workflows for the single cell pre-processing are available that do not make these assumptions. For example the `SCTransform()` normalisation workflow is an alternative method and its replaces the need to run `NormalizeData`, `FindVariableFeatures`, or `ScaleData`.

```{r total_exp_after_lognorm}
hist(
  colSums(pbmc[['RNA']]$data),
  breaks = 100,
  main = "Total expression after normalisation",
  xlab = "Sum of expression"
)
```

## Identification of highly variable features (feature selection)

Once the data is normalised, the next step is to find genes are vary between single cells since genes that are constant among all cells have no distinguishing power. These are genes that exhibit high cell-to-cell variation in the dataset (i.e., they are highly expressed in some cells, and lowly expressed in others) and it has been found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.

The `FindVariableFeatures()` function calculates the average expression and dispersion for each gene, places these genes into bins, and then calculates a Z-score for dispersion within each bin. This is interpreted as take each gene, calculate the average expression and variance of the gene across the `r ncol(pbmc@assays$RNA$counts)` barcodes, categorise genes into 20 bins (default is 20) based on their expression and variance, and finally normalise the variance in each bin.

This was the same approach in [Macosko et al.](https://www.ncbi.nlm.nih.gov/pubmed/26000488) and new methods for detecting genes with variable expression patterns have been implemented in Seurat. The parameters used below are typical settings for UMI data that is normalised to a total of 10,000 molecules and will identify 2,000 variable genes. These genes will be used in downstream analyses, like PCA. The tutorial recommends that users should explore the parameters themselves since each dataset is different.

> vst: First, fits a line to the relationship of log(variance) and log(mean) using local polynomial regression (loess). Then standardizes the feature values using the observed mean and expected variance (given by the fitted line). Feature variance is then calculated on the standardized values after clipping to a maximum (see clip.max parameter). 

```{r find_variable_features}
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000, verbose = FALSE)
```

Double check that 2000 genes are returned.

```{r number_of_variable_features}
length(VariableFeatures(pbmc))
```

Identify the 10 most highly variable genes

```{r top10_variable_features}
top10 <- head(VariableFeatures(pbmc), 10)
top10
```

Plot variable features with and without labels

```{r plot_top10_variable_features, fig.width=10, fig.height=6}
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2
```

## Scaling the data

Next, we apply a linear transformation ("scaling") that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The `ScaleData()` function:

* Shifts the expression of each gene, so that the mean expression across cells is 0
* Scales the expression of each gene, so that the variance across cells is 1
    * This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate
* The results of this are stored in `pbmc[["RNA"]]$scale.data`
* By default, only variable features are scaled but you can specify the features argument to scale additional features

```{r scale_data_all_genes}
all.genes <- rownames(pbmc)
pbmc <- ScaleData(pbmc, features = all.genes, verbose = FALSE)
dim(pbmc[["RNA"]]$scale.data)
```

Scale data shifts the average to zero.

```{r total_exp_after_lognorm_after_scaling}
hist(
  colSums(pbmc[['RNA']]$scale.data),
  breaks = 100,
  main = "Total expression after scaling",
  xlab = "Sum of expression"
)
abline(v = mean(colSums(pbmc@assays$RNA$scale.data)), col = 2, lty = 3)
```

In Seurat, we the `ScaleData()` function is also used to remove unwanted sources of variation from a single-cell dataset. For example, we could "regress out" heterogeneity associated with (for example) cell cycle stage, or mitochondrial contamination.

```{r scale_data_all_genes_regress_out}
bench::system_time(
  pbmc_regress <- ScaleData(pbmc, vars.to.regress = "percent.mt", verbose = FALSE)
)
pbmc_no_regress <- ScaleData(pbmc, verbose = FALSE)

dim(pbmc_regress@assays$RNA$scale.data)
dim(pbmc_no_regress@assays$RNA$scale.data)
```

Compare regress with without regress.

```{r regress_vs_no_regress}
plot(
  pbmc_no_regress@assays$RNA$scale.data,
  pbmc_regress@assays$RNA$scale.data,
  pch = 16,
  cex = 0.3
)
abline(a = 0, b = 1, lty = 3, col = 2)
```

However, the Seurat developers strongly recommend the use of their new normalisation workflow, `SCTransform()`. The method is described in [this paper](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02584-9), with a separate [vignette using Seurat](https://satijalab.org/seurat/articles/sctransform_vignette). As with `ScaleData()`, the function `SCTransform()` also includes a `vars.to.regress` parameter.

## Perform linear dimensional reduction

Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but a different subset can be defined using features argument (if you do want to use a custom subset of features, make sure you pass these to `ScaleData` first).

For the first principal components, Seurat outputs a list of genes with the most positive and negative loadings, representing modules of genes that exhibit either correlation (or anti-correlation) across single-cells in the dataset.

```{r run_pca}
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc), verbose = FALSE)
```

Seurat provides several useful ways of visualising both cells and features that define the PCA, including `VizDimReduction()`, `DimPlot()`, and `DimHeatmap()`.

```{r pos_neg_cor}
print(pbmc[["pca"]], dims = 1:5, nfeatures = 5)
```

Visualise top genes associated with reduction components.

```{r viz_dim_loadings, fig.height=7, fig.width=8}
VizDimLoadings(pbmc, dims = 1:2, reduction = "pca")
```

PC_1 versus PC_2.

```{r dim_plot_pca}
DimPlot(pbmc, reduction = "pca") + NoLegend()
```

In particular `DimHeatmap()` allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores. Setting cells to a number, plots the "extreme" cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets.

```{r dim_heatmap}
DimHeatmap(pbmc, dims = 1, cells = 500, balanced = TRUE)
```

Additional PCs.

```{r fig.height=12, fig.width=8}
DimHeatmap(pbmc, dims = 1:15, cells = 500, balanced = TRUE)
```

[Variance explained](https://github.com/satijalab/seurat/issues/982) by each PC.

```{r variance_explained}
# manually calculate
total_variance <- sum(
  matrixStats::rowVars(pbmc[['RNA']]$scale.data[VariableFeatures(pbmc), ])
)

stopifnot(all.equal(total_variance, pbmc@reductions$pca@misc$total.variance))

eig_values <- (pbmc@reductions$pca@stdev)^2
eig_values / total_variance
```

## Determine the dimensionality of the dataset 

To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a "metafeature" that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many components should we choose to include? 10? 20? 100?

In Macosko et al, we implemented a resampling test inspired by the JackStraw procedure. While still available in Seurat (see previous vignette), this is a slow and computationally expensive procedure, and we is no longer routinely used in single cell analysis.

An alternative heuristic method generates an "Elbow plot": a ranking of principle components based on the percentage of variance explained by each one (`ElbowPlot()` function). In this example, we can observe an "elbow" around PC9-10, suggesting that the majority of true signal is captured in the first 10 PCs.

```{r elbow_plot}
# to reproduce ElbowPlot
# plot(1:length(pbmc@reductions$pca@stdev), pbmc@reductions$pca@stdev, pch = 16)
ElbowPlot(pbmc)
```

Identifying the true dimensionality of a dataset can be challenging/uncertain for the user. The Seurat developers therefore suggest multiple approaches.

1. The first is more supervised, exploring PCs to determine relevant sources of heterogeneity, and could be used in conjunction with GSEA for example.
2. The second is using `ElbowPlot()`
3. The third is a heuristic that is commonly used, and can be calculated instantly.

In this example, we might have been justified in choosing anything between PC 7-12 as a cutoff. 10 was chosen, but users are encouraged to consider the following:

* Dendritic cell and NK aficionados may recognise that genes strongly associated with PCs 12 and 13 define rare immune subsets (i.e. MZB1 is a marker for plasmacytoid DCs). However, these groups are so rare, they are difficult to distinguish from background noise for a dataset of this size without prior knowledge.
* Users are encouraged to repeat downstream analyses with a different number of PCs (10, 15, or even 50!). As you will observe, the results often do not differ dramatically.
* Users are advised to err on the higher side when choosing this parameter. For example, performing downstream analyses with only 5 PCs does significantly and adversely affect results.

## Clustering the cells

Seurat applies a graph-based clustering approach, building upon initial strategies in (Macosko et al). Importantly, the distance metric which drives the clustering analysis (based on previously identified PCs) remains the same. However, Seurat's approach to partitioning the cellular distance matrix into clusters has dramatically improved. This approach was heavily inspired by other graph-based clustering approaches to scRNA-seq data [SNN-Cliq, Xu and Su, Bioinformatics, 2015] and CyTOF data [PhenoGraph, Levine et al., Cell, 2015]. Briefly, these methods embed cells in a graph structure - for example a K-nearest neighbor (kNN) graph, with edges drawn between cells with similar feature expression patterns, and then attempt to partition this graph into highly interconnected "quasi-cliques" or "communities".

As in PhenoGraph, a KNN graph is constructed based on the Euclidean distance in PCA space, and refinement of the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). This step is performed using the `FindNeighbors()` function, and takes as input the previously defined dimensionality of the dataset (first 10 PCs).

To cluster the cells, modularity optimisation techniques are applied such as the Louvain algorithm (default) or SLM [SLM, Blondel et al., Journal of Statistical Mechanics], to iteratively group cells together, with the goal of optimising the standard modularity function. The `FindClusters()` function implements this procedure, and contains a resolution parameter that sets the "granularity" of the downstream clustering, with higher values leading to a greater number of clusters. Setting this parameter between 0.4-1.2 typically returns good results for single-cell datasets of around 3K cells. Optimal resolution often increases for larger datasets. The clusters can be found using the `Idents()` function.

```{r find_neighbours_and_clusters}
pbmc <- FindNeighbors(pbmc, dims = 1:10, verbose = FALSE)
pbmc <- FindClusters(pbmc, resolution = 0.5, verbose = FALSE)
```

Look at cluster IDs of the first 5 cells

```{r head_cluster_ids}
head(Idents(pbmc), 5)
```

## Non-linear dimensional reduction

Seurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualise and explore datasets. The goal of these algorithms is to learn any underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined using `FindNeighbors()` and `FindClusters()` should co-localise on these dimension reduction plots.

While 2D visualisation techniques like tSNE and UMAP are valuable tools for exploring datasets, all visualisation techniques have limitations, and cannot fully represent the complexity of the underlying data. In particular, these methods aim to preserve local distances in the dataset (i.e., ensuring that cells with very similar gene expression profiles co-localise), but often do not preserve more global relationships. Therefore it is fine to leverage techniques like UMAP for visualisation, but avoid drawing biological conclusions solely on the basis of visualisation techniques.

```{r run_umap}
pbmc <- RunUMAP(pbmc, dims = 1:10, verbose = FALSE)
```

Note that you can set `label = TRUE` or use the `LabelClusters()` function to help label individual clusters

```{r dim_plot_umap}
DimPlot(pbmc, reduction = "umap")
```

## Finding differentially expressed features

Seurat can find markers that define clusters via differential expression (DE). By default, it identifies positive and negative markers of a single cluster (specified in ident.1), compared to **all** other cells. `FindAllMarkers()` automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells.

In Seurat v5, the {presto} package is used to dramatically improve the speed of DE analysis, particularly for large datasets. You can examine the documentation for this function (`?FindMarkers`) to explore the `min.pct` and `logfc.threshold` parameters, which can be increased in order to increase the speed of DE testing.

Find all markers of cluster 2.

```{r find_markers_of_cluster_2}
cluster2.markers <- FindMarkers(pbmc, ident.1 = 2)
head(cluster2.markers, n = 5)
```

Find all markers distinguishing cluster 5 from clusters 0 and 3

```{r find_markers_of_cluster_5}
cluster5.markers <- FindMarkers(pbmc, ident.1 = 5, ident.2 = c(0, 3))
head(cluster5.markers, n = 5)
```

Find markers for every cluster compared to all remaining cells, report only the positive ones.

```{r find_all_markers, warning=FALSE, message=FALSE}
pbmc.markers <- FindAllMarkers(pbmc, only.pos = TRUE, verbose = FALSE)
pbmc.markers |>
  dplyr::group_by(cluster) |>
  dplyr::filter(avg_log2FC > 1)
```

Seurat has several tests for differential expression which can be set with the `test.use` parameter (see the [Differential expression testing vignette](https://satijalab.org/seurat/articles/de_vignette)). For example, the ROC test returns the "classification power" for any individual marker (ranging from 0 - random, to 1 - perfect).

```{r de_roc}
cluster0.markers <- FindMarkers(pbmc, ident.1 = 0, logfc.threshold = 0.25, test.use = "roc", only.pos = TRUE)
```

Seurat has included several tools for visualising marker expression. `VlnPlot()` (shows expression probability distributions across clusters), and `FeaturePlot()` (visualises feature expression on a tSNE or PCA plot) are commonly used visualisations. There are also `RidgePlot()`, `CellScatter()`, and `DotPlot()` as additional methods to view your dataset.

```{r vln_plot_ms4a1_cd79a}
VlnPlot(pbmc, features = c("MS4A1", "CD79A"))
```

You can plot raw counts as well.

```{r vln_plot_raw_counts}
VlnPlot(pbmc, features = c("NKG7", "PF4"), layer = "counts", log = TRUE)
```

Feature plot with a list of genes.

```{r feature_plot_gene_list, fig.height=8, fig.width=10}
FeaturePlot(
  pbmc,
  features = c("MS4A1", "GNLY", "CD3E", "CD14", "FCER1A", "FCGR3A", "LYZ", "PPBP", "CD8A")
)
```

`DoHeatmap()` generates an expression heatmap for given cells and features. In this case, we are plotting the top 20 markers (or all markers if less than 20) for each cluster.

```{r plot_all_markers, fig.height=10, fig.width=12}
pbmc.markers |>
  dplyr::group_by(cluster) |>
  dplyr::filter(avg_log2FC > 1) |>
  dplyr::slice_head(n = 10) |>
  dplyr::ungroup() -> top10

DoHeatmap(pbmc, features = top10$gene) + NoLegend()
```

## Assigning cell type identity to clusters

Fortunately in the case of this dataset, we can use canonical markers to easily match the unbiased clustering to known cell types:

Cluster ID | Markers       | Cell Type
-----------|---------------|----------
0          | IL7R, CCR7    | Naive CD4+ T 
1          | CD14, LYZ     | CD14+ Mono
2          | IL7R, S100A4  | Memory CD4+ 
3          | MS4A1         | B 
4          | CD8A          | CD8+ T 
5          | FCGR3A, MS4A7 | FCGR3A+ Mono
6          | GNLY, NKG7    | NK 
7          | FCER1A, CST3  | DC
8          | PPBP          | Platelet

```{r new_cluster_ids}
new.cluster.ids <- c("Naive CD4 T", "CD14+ Mono", "Memory CD4 T", "B", "CD8 T", "FCGR3A+ Mono",
    "NK", "DC", "Platelet")
names(new.cluster.ids) <- levels(pbmc)
pbmc <- RenameIdents(pbmc, new.cluster.ids)
DimPlot(pbmc, reduction = "umap", label = TRUE, pt.size = 0.5) + NoLegend()
```

Customise plot using {ggplot2}.

```{r dim_plot_new_ids, fig.height=7, fig.width=12}
library(ggplot2)
DimPlot(pbmc, reduction = "umap", label = TRUE, label.size = 4.5) + xlab("UMAP 1") +
  ylab("UMAP 2") +
  theme(axis.title = element_text(size = 18), legend.text = element_text(size = 18)) +
  guides(colour = guide_legend(override.aes = list(size = 10)))
```

## From AnnData

Download [1k PBMCs](https://openproblems.bio/datasets/openproblems_v1/tenx_1k_pbmc/) in AnnData format from [Open Problems in Single-Cell Analysis](https://openproblems.bio/).

```
aws s3 cp --no-sign-request s3://openproblems-data/resources/datasets/openproblems_v1/tenx_1k_pbmc/l1_sqrt/dataset.h5ad .
```
