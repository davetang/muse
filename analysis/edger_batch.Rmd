---
title: "edgeR with batch effects"
date: "`r Sys.Date()`"
output:
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
```

## Batch Effects

From [Batch Effects](https://genomicsclass.github.io/book/pages/intro_to_batch_effects.html).

One often overlooked complication with high-throughput studies is batch effects, which occur because measurements are affected by laboratory conditions, reagent lots, and personnel differences. This becomes a major problem when batch effects are confounded with an outcome of interest and lead to incorrect conclusions. In this chapter, we describe batch effects in detail: how to detect, interpret, model, and adjust for batch effects.

Batch effects are the biggest challenge faced by genomics research, especially in the context of precision medicine. The presence of batch effects in one form or another has been reported among most, if not all, high-throughput technologies [Leek et al. (2010) Nature Reviews Genetics 11, 733-739]. But batch effects are not specific to genomics technology. In fact, in a 1972 paper, WJ Youden describes batch effects in the context of empirical estimates of physical constants. He pointed out the "subjective character of present estimates" of physical constants and how estimates changed from laboratory to laboratory. For example, in Table 1, Youden shows the following estimates of the astronomical unit from different laboratories. The reports included an estimate of spread (what we now would call a confidence interval).

```{r astronomical_units,echo=FALSE,message=FALSE,fig.cap="Estimates of the astronomical unit with estimates of spread, versus year it was reported. The two laboratories that reported more than one estimate are shown in color."}
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/astronomicalunit.csv"
filename <- paste0("data/", basename(url))
if (!file.exists(filename)) download.file(url, destfile=filename)
dat <- read.csv(filename)
year <-  jitter(dat[,2]) ##add jitter so points are not on top of each other

##Use color to denote the labs that reported more than one measurement
labs <- as.character(dat[,1]) ##what lab did it
labs[ !labs%in%c("Jodrell Bank","Spencer Jones")] <- "Others"
labs <- factor(labs, levels=c("Others","Spencer Jones","Jodrell Bank"))
cols=as.numeric(labs)

current <- 92.956039 ##this is the current estimate in millions of mph

plot(year, dat[,3], ylim=c(min(dat[,4]),max(dat[,5])), pch=16, col=cols, 
     xlab="Year",ylab="Astronomical unit (millions of miles)")
for(i in 1:nrow(dat))
  lines(c(year[i],year[i]),c(dat[i,4],dat[i,5]),col=cols[i],lwd=3)
legend("topright", legend=levels(labs), col=seq_along( labs ) ,cex=0.75, lty=1,pch=16)
abline(h=current,lty=2)
text(1905,current,"Current estimate",pos=3)
```

Judging by the variability across labs and the fact that the reported bounds do not explain this variability, clearly shows the presence of an effect that differs across labs, but not within. This type of variability is what we call a batch effect. Note that there are laboratories that reported two estimates (red and green) and batch effects are seen across the two different measurements from the same laboratories as well. 

We can use statistical notation to precisely describe the problem. The scientists making these measurements assumed they observed:

$$
Y_{i,j} = 
\mu + \varepsilon_{i,j}, j=1,\dots,N
$$

with $Y_{i,j}$ the $j$-th measurement of laboratory $i$, $\mu$ the true physical constant, and $\varepsilon_{i,j}$ independent measurement error. To account for the variability introduced by $\varepsilon_{i,j}$, we compute standard errors from the data. As we saw earlier in the book, we estimate the physical constant with the average of the $N$ measurements...

$$
\bar{Y}_i = 
\frac{1}{N} \sum_{i=1}^{N} Y_{i,j}
$$

.. and we can construct a confidence interval by:

$$
\bar{Y}_i 
 \pm 2 s_i / \sqrt{N} \mbox{ with }
s_i^2= 
\frac{1}{N-1} \sum_{i=1}^N (Y_{i,j} - 
\bar{Y}_i)^2
$$

However, this confidence interval will be too small because it does not catch the batch effect variability. A more appropriate model is:

$$
Y_{i,j} = \mu +
\gamma_i + \varepsilon_{i,j}, j=1, \dots, N
$$

with $\gamma_i$ a laboratory specific bias or _batch effect_. 

From the plot it is quite clear that the variability of $\gamma$ across laboratories is larger than the variability of $\varepsilon$ within a lab. The problem here is that there is no information about $\gamma$ in the data from a single lab. The statistical term for the problem is that $\mu$ and $\gamma$ are unidentifiable. We can estimate the sum $\mu_i+\gamma_i$ , but we can't distinguish one from the other.

We can also view $\gamma$ as a random variable. In this case, each laboratory has an error term $\gamma_i$ that is the same across measurements from that lab, but different from lab to lab. Under this interpretation the problem is that: 

$$
 s_i / \sqrt{N} \mbox{ with } 
 s_i^2= 
\frac{1}{N-1} \sum_{i=1}^N (Y_{ij} - 
\bar{Y}_i)^2
$$

is an underestimate of the standard error since it does not account for the within lab correlation induced by $\gamma$.

With data from several laboratories we can in fact estimate the $\gamma$, if we assume they average out to 0. Or we can consider them to be random effects and simply estimate a new estimate and standard error with all measurements. Here is a confidence interval treating each reported average as a random observation:

```{r}
avg <- mean(dat[,3])
se <- sd(dat[,3]) / sqrt(nrow(dat))
```

```{r,echo=FALSE}
cat("95% confidence interval is: [",avg-1.96*se,",", avg+1.96*se,"]")
cat("which does include the current estimate is:",current)
```

Youden's paper also includes batch effect examples from more recent estimates of the speed of light, as well as estimates of the gravity constant. Here we demonstrate the widespread presence and complex nature of batch effects in high-throughput biological measurements. 

## edgeR

[edgeR](https://bioconductor.org/packages/release/bioc/html/edgeR.html) carries out:

> Differential expression analysis of RNA-seq expression profiles with biological replication. Implements a range of statistical methodology based on the negative binomial distributions, including empirical Bayes estimation, exact tests, generalized linear models and quasi-likelihood tests. As well as RNA-seq, it be applied to differential signal analysis of other types of genomic data that produce read counts, including ChIP-seq, ATAC-seq, Bisulfite-seq, SAGE and CAGE. 

In this notebook we will be following Section 4.2 RNA-Seq of pathogen inoculated arabidopsis with batch effects on page 55 of the [edgeR user guide](https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf).

## Installation

Install using `BiocManager::install()`.

```{r install_edger, eval=FALSE}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("edgeR")
```

Load.

```{r load_edger}
library(edgeR)
packageVersion("edgeR")
```

## Data

`arab.rds` was downloaded from WEHI's [Bioinformatics page for edgeR](https://bioinf.wehi.edu.au/edgeR/) on my web server. (There have been more than one occasion where my personal web server out lasted a tool's webpage, so I prefer referring to my web server.)

```{r download_data}
count_rds <- "data/arab.rds"
if(!file.exists(count_rds)){
  download.file(url = "https://davetang.org/file/arab.rds", destfile = count_rds)
}

stopifnot(tools::md5sum(count_rds) == '4af4a2e351279b73cb53a58991b0e004')
```

Load.

```{r arab}
arab <- readRDS(count_rds)
head(arab)
```

## DGEList

There are two experimental factors:

1. treatment (`hrcc` vs. `mock`) and
2. the time that each replicate was conducted.

```{r conditions}
Treat <- factor(substring(colnames(arab),1,4))
Treat <- relevel(Treat, ref="mock")
Treat

Time <- factor(substring(colnames(arab),5,5))
Time
```

Create a DGEList object.

```{r dgelist}
y <- DGEList(counts=arab, group=Treat)
y
```

## Filtering and normalisation

Filter.

```{r filter_by_expr}
keep <- filterByExpr(y)
table(keep)
y <- y[keep, , keep.lib.sizes=FALSE]
```

TMM normalization.

```{r tmm}
y <- normLibSizes(y)
y$samples
```

## Exploratory analysis

MDS.

```{r mds}
plotMDS(y, col=rep(1:2, each=3))
```

Examine consistency of the three replicates by computing predictive log2-fold-changes (logFC) for the treatment separately for the three times. The `predFC()` function:

> Computes estimated coefficients for a NB glm in such a way that the log-fold-changes are shrunk towards zero.

```{r pred_fc}
design <- model.matrix(~Time+Time:Treat)
logFC <- predFC(y,design,prior.count=1,dispersion=0.05)
head(logFC)
```

The logFC at the three times are positively correlated with one another.

```{r pred_fc_cor}
cor(logFC[,4:6])
```

Calculate my own log FC to confirm what `predFC()` is doing for timepoint `1`.

```{r my_logfc}
my_genes <- row.names(logFC)
hrcc1 <- arab[my_genes, 'hrcc1']
mock1 <- arab[my_genes, 'mock1']

my_logfc <- log(hrcc1 / (mock1 + 0.1))
plot(logFC[, 4], my_logfc, pch = 16, main = cor(logFC[, 4], my_logfc, method = "spearman"))
```

## Design matrix

Before we fit GLMs, we need to define our design matrix based on the experimental design. We want to test for differential expressions between `hrcc` challenged and mock-inoculated samples within batches, i.e. adjusting for differences between batches. In statistical terms, this is an additive linear model. So the design matrix is created as:

```{r design}
design <- model.matrix(~Time+Treat)
rownames(design) <- colnames(y)
design
```

Switch the covariates around (for testing purposes).

```{r design2}
design2 <- model.matrix(~Treat+Time)
rownames(design2) <- colnames(y)
design2
```

## Dispersion estimation

Estimate the genewise dispersion estimates over all genes, allowing for a possible abundance trend. The estimation is also robustified against potential outlier genes.

```{r est_disp}
y <- estimateDisp(y, design, robust=TRUE)
y$common.dispersion

y2 <- estimateDisp(y, design2, robust=TRUE)
y2$common.dispersion
```

Plot.

```{r plot_bcv}
plotBCV(y)
```

The QL dispersions can be estimated using the `glmQLFit()` function, and then be visualised with the `plotQLDisp()` function.

```{r fit}
fit <- glmQLFit(y, design, robust=TRUE)
plotQLDisp(fit)

fit2 <- glmQLFit(y2, design2, robust=TRUE)
plotQLDisp(fit2)
```

## Differential expression

Now we test for significant differential expression in each gene using the QL F-test.

First we check whether there was a genuine need to adjust for the experimental times. We do this by testing for differential expression between the three times. There is considerable differential expression, justifying our decision to adjust for the batch effect.

```{r glm_ql_ftest}
qlf <- glmQLFTest(fit, coef=2:3)
summary(decideTests(qlf))
```

Now conduct QL F-tests for the pathogen effect and show the top genes. By default, the test is for the last coefficient in the design matrix, which in this case is the treatment effect:

```{r glm_ql_ftest2}
qlf2 <- glmQLFTest(fit)
summary(decideTests(qlf2))
```

Save DE genes.

```{r save_de_genes}
topTags(qlf2, n = Inf) |>
  as.data.frame() |>
  dplyr::filter(FDR < 0.05) |>
  row.names() -> de_genes

length(de_genes)
```

Test.

```{r glm_ql_ftest3}
qlf3 <- glmQLFTest(fit2, coef=2)
summary(decideTests(qlf3))
```

Closer look at the individual counts-per-million for the top genes. The top genes are very consistent across the three replicates:

```{r top_genes}
top <- rownames(topTags(qlf2))
cpm(y)[top,]
```

Plot.

```{r plot_md}
plotMD(qlf2)
abline(h=c(-1,1), col="blue")
```

## No correction

No correction.

```{r no_correction}
count_rds <- "data/arab.rds"
arab <- readRDS(count_rds)

Treat <- factor(substring(colnames(arab),1,4))
Treat <- relevel(Treat, ref="mock")

y <- DGEList(counts=arab, group=Treat)
keep <- filterByExpr(y)
y <- y[keep, , keep.lib.sizes=FALSE]

y <- normLibSizes(y)

design <- model.matrix(~Treat)
rownames(design) <- colnames(y)

y <- estimateDisp(y, design, robust=TRUE)

fit <- glmQLFit(y, design, robust=TRUE)

qlf <- glmQLFTest(fit)

summary(decideTests(qlf))
```

Compare DE genes with DE genes called with batch effect correction. More sensitive testing with batch correction.

```{r compare_de_genes}
topTags(qlf, n = Inf) |>
  as.data.frame() |>
  dplyr::filter(FDR < 0.05) |>
  row.names() -> de_genes_no_correction

gplots::venn(
  list(
    corrected = de_genes,
    not_corrected = de_genes_no_correction
  )
)
```

Top genes from no correction test.

```{r top_genes_no_correction}
top <- rownames(topTags(qlf))
cpm(y)[top,]
```

Plot.

```{r plot_md_no_correction}
plotMD(qlf)
abline(h=c(-1,1), col="blue")
```

## Incorrect order

Recall that the test is for the last coefficient in the design matrix, which in this case is `Time3`.

```{r incorrect_order}
count_rds <- "data/arab.rds"
arab <- readRDS(count_rds)

Treat <- factor(substring(colnames(arab),1,4))
Treat <- relevel(Treat, ref="mock")
Time <- factor(substring(colnames(arab),5,5))

y <- DGEList(counts=arab, group=Treat)
keep <- filterByExpr(y)
y <- y[keep, , keep.lib.sizes=FALSE]

y <- normLibSizes(y)

design <- model.matrix(~Treat+Time)
rownames(design) <- colnames(y)
design
```

Continue the analysis.

```{r incorrect_order_cont}
y <- estimateDisp(y, design, robust=TRUE)

fit <- glmQLFit(y, design, robust=TRUE)

qlf <- glmQLFTest(fit)

summary(decideTests(qlf))

top <- rownames(topTags(qlf))
cpm(y)[top,]
```

The top genes are different between timepoint 3 and the other timepoints!
