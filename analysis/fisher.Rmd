---
title: "Fisher's Exact Test"
date: "`r Sys.Date()`"
output:
  workflowr::wflow_html:
    toc: true
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
```

## Global test

If you have more than two clusters, Fisher's Exact Test becomes a generalised Fisher's Exact Test (also known as Fisher-Freeman-Halton test), because the regular Fisher's test is for 2x2 tables.

For larger tables, people often use:

* Chi-squared test (if counts are not too small)
* Generalised Fisher's Exact Test (exact test and have a small sample)

Create cluster table.

```{r cluster_table}
treated   <- c(50, 60, 40, 30, 80, 90, 20, 15, 70, 45)
untreated <- c(55, 50, 35, 25, 85, 95, 25, 20, 65, 40)

cluster_table <- rbind(treated, untreated)
colnames(cluster_table) <- paste0("cluster", 0:9)
rownames(cluster_table) <- c("Treated", "Untreated")
cluster_table
```

Chi-squared Test.

```{r chi_squared}
chisq_test <- chisq.test(cluster_table)
chisq_test
```

Generalised Fisher's Exact Test.

* `workspace` - an integer specifying the size of the workspace used in the network algorithm. In units of 4 bytes. Only used for non-simulated p-values larger than 2×22×2 tables. Since R version 3.5.0, this also increases the internal stack size which allows larger problems to be solved, however sometimes needing hours. In such cases, simulate.p.values=TRUE may be more reasonable.

```{r fishers_test}
fisher_test <- fisher.test(cluster_table, workspace=2e8)
fisher_test
```

Another cluster table.

```{r cluster_table2}
treated2   <- c(200, 60, 40, 30, 80, 90, 20, 15, 70, 45)
untreated2 <- c(55, 50, 35, 30, 85, 95, 25, 20, 75, 40)

cluster_table2 <- rbind(treated2, untreated2)
colnames(cluster_table2) <- paste0("cluster", 0:9)
rownames(cluster_table2) <- c("Treated", "Untreated")
cluster_table2
```

Chi-squared Test; Chi-squared is valid when expected counts are reasonably large (> 5 cells per condition per cluster).

```{r chi_squared2}
chisq_test2 <- chisq.test(cluster_table2)
chisq_test2
```

Generalised Fisher's Exact Test.

* `simulate.p.value` - a logical indicating whether to compute p-values by Monte Carlo simulation, in larger than 2×22×2 tables.

```{r fishers_test2}
fisher_test2 <- fisher.test(cluster_table2, simulate.p.value = TRUE)
fisher_test2
```

Notes:

* Fisher's and Chi-squared tests operate on contingency tables of counts, not proportions.
* They intrinsically consider the marginal totals (total treated cells, total untreated cells, total cells in each cluster) when computing expected frequencies.
* If you use percentages or normalised counts, you actually distort the expected distribution.

```{r cluster_table3}
treated3   <- c(50, 60, 40, 30, 80, 90, 20, 15, 70, 45)
untreated3 <- untreated*3

cluster_table3 <- rbind(treated3, untreated3)
colnames(cluster_table3) <- paste0("cluster", 0:9)
rownames(cluster_table3) <- c("Treated", "Untreated")

chisq.test(cluster_table3)
```

## Per-cluster Fisher's Exact Test

Perform one Fisher's Exact Test per cluster.

```{r fisher_per_cluster}
treated   <- c(200, 60, 40, 30, 80, 90, 20, 15, 70, 45)
untreated <- c(55, 50, 35, 30, 85, 95, 25, 20, 75, 40)
clusters <- paste0("cluster", 0:9)

total_treated <- sum(treated)
total_untreated <- sum(untreated)

res <- purrr::map(seq_along(clusters), \(i){
  contingency_table <- matrix(
    c(
      treated[i], total_treated - treated[i],
      untreated[i], total_untreated - untreated[i]
    ),
    nrow=2,
    byrow=TRUE
  )
  
  fisher_res <- fisher.test(contingency_table)
  list(
    table = contingency_table,
    stat = fisher_res
  )
})

res[[1]]
```

As a table with multiple testing correction.

```{r fisher_per_cluster_table}
data.frame(
  Cluster = clusters,
  Treated = treated,
  Untreated = untreated,
  pvalue = purrr::map_dbl(res, \(x) x$stat$p.value),
  odds_ratio = purrr::map_dbl(res, \(x) x$stat$estimate)
) -> res_df

res_df$padj <- p.adjust(res_df$pvalue, method = "BH")
res_df$log2_odds_ratio <- log2(res_df$odds_ratio)

res_df
```

Volcano plot.

```{r volcano_plot}
library(ggplot2)

ggplot(res_df, aes(x = log2_odds_ratio, y = -log10(pvalue), label=Cluster)) +
  geom_point(size=3) +
  geom_text(nudge_y = 0.3) +
  geom_hline(yintercept = -log10(0.05), linetype="dashed", color="red") +
  xlab("Log2 Odds Ratio") + ylab("-log10(p-value)") +
  theme_minimal()
```

Plot Cluster Proportions.

```{r cluster_proportions}
prop_df <- data.frame(
  Cluster = rep(clusters, 2),
  Condition = rep(c("Treated", "Untreated"), each=length(clusters)),
  Proportion = c(treated / total_treated, untreated / total_untreated)
)

ggplot(prop_df, aes(x=Cluster, y=Proportion, fill=Condition)) +
  geom_bar(stat="identity", position="dodge") +
  ylab("Proportion of Cells") +
  theme_minimal() +
  theme(axis.title.x = element_blank())
```
 
If using Seurat, just use `table(Idents(seurat_obj), seurat_obj$condition)` to create the contingency table and carry out the steps as per above.

## Notes

The **odds ratio** compares the odds of finding a cell in a specific cluster **in treated cells** versus **in untreated cells**.

For example:

|           | Cluster A | Not Cluster A | Total |
|-----------|-----------|---------------|-------|
| Treated   | 200       | 450           | 650   |
| Untreated | 55        | 455           | 510   |

The **odds** of being in Cluster A:

* For treated cells:  

$$ {Odds}_{\text{treated}} = \frac{200}{450} = 0.4444 $$
  
* For untreated cells:  

$$ \text{Odds}_{\text{untreated}} = \frac{55}{455} = 0.1209 $$

So the **odds ratio** is:

$$ \text{OR} = \frac{0.4444}{0.1209} \approx 3.6758 $$

```{r check_odds_ratio}
res_df[1, ]
```

| Odds Ratio | Interpretation                                 |
|------------|------------------------------------------------|
| OR = 1     | No difference between treated and untreated    |
| OR > 1     | Treated cells are **enriched** in this cluster |
| OR < 1     | Treated cells are **depleted** in this cluster |

In the example above, OR ~ 3.67 means treated cells are ~3.67 times more likely to be in Cluster 0 than untreated cells.

Taking the `log2` of the odds ratio is common because:

1. It makes the scale symmetric:
   - `log2(OR = 2)` = `1`  
   - `log2(OR = 0.5)` = `-1`
2. It helps with plotting (like in volcano plots) where you want to easily spot:
   - Positive values = enrichment
   - Negative values = depletion
   - Zero = no change

- `log2(OR) = 1` means cells are **2x more likely** to be in that cluster if treated.
- `log2(OR) = -1` means cells are **2x less likely** (i.e., enriched in untreated).
- `log2(OR) = 0` means no difference between treated and untreated.
