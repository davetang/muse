---
title: "Seurat v4 versus v5"
date: "`r Sys.Date()`"
output:
  workflowr::wflow_html:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# https://stackoverflow.com/questions/30237310/setting-work-directory-in-knitr-using-opts-chunksetroot-dir-doesnt-wor
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
library(tidyverse)
library(Seurat)
```

## sctransform

The paper [Comparison and evaluation of statistical error models for scRNA-seq](https://link.springer.com/article/10.1186/s13059-021-02584-9) is the basis for the default approach used in Seurat version 5. The following is text from the paper:

* Heterogeneity in single-cell RNA-seq (scRNA-seq) data is driven by multiple sources, including biological variation in cellular state as well as technical variation introduced during experimental processing. Deconvolving these effects is a key challenge for preprocessing workflows.
    * Separating biological heterogeneity across cells that corresponds to differences in cell type and state from alternative sources of variation represents a key analytical challenge in the normalization and preprocessing of single-cell RNA-seq data.
* Data normalization aims to adjust for differences in cellular sequencing depth, which collectively arise from fluctuations in cellular RNA content, efficiency in lysis and reverse transcription, and stochastic sampling during next-generation sequencing.
* **Variance stabilisation aims to address the confounding relationship between gene abundance and gene variance, and to ensure that both lowly and highly expressed genes can contribute to the downstream definition of cellular state**.

Using statistical models like Generalised Linear Models:

* Two recent studies proposed to use generalized linear models (GLMs), where cellular sequencing depth was included as a covariate, as part of scRNA-seq preprocessing workflows.
* The sctransform approach utilizes the **Pearson residuals from negative binomial regression as input to standard dimensional reduction techniques**, while GLM-PCA focuses on a generalized version of principal component analysis (PCA) for data with Poisson-distributed errors.
* More broadly, multiple techniques aim to learn a latent state that captures biologically relevant cellular heterogeneity using either matrix factorization or neural networks, alongside a defined error model that describes the variation that is not captured by the latent space.

If a regression model doesn't fully explain variability, the residuals might contain structure that another technique can capture to uncover hidden patterns. For example, if a regression model captures main trends, applying Principal Component Analysis (PCA) on residuals can find underlying structures in the unexplained variance. Another use case can be clustering on residuals to group data points based on deviations from a model.

Parameterising statistical models:

* Likelihood-based approaches require an explicit definition of a statistical error model for scRNA-seq, and there is little consensus on how to define or parameterize this model.
* Multiple groups have utilized a Poisson error model but others argue that the data exhibit evidence of overdispersion, requiring the use of a negative-binomial (NB) distribution.
* Methods that assume a NB distribution have different methods to parameterize their model.
    * A recent study argued that fixing the NB inverse overdispersion parameter $\theta$ to a single value is an appropriate estimate of technical overdispersion for all genes in all scRNA-seq datasets, while others propose learning unique parameter values for each gene in each dataset.
* This lack of consensus is further exemplified by the scvi-tools suite, which supports nine different methods for parameterizing error models.
* The purpose of this error model is to describe and quantify heterogeneity that is not captured by biologically relevant differences in cell state, and highlights a specific question: **How can we model the observed variation in gene expression for an scRNA-seq experiment conducted on a biologically "homogeneous" population?**

## Error and variance

* Error modeling refers to capturing and understanding the **uncertainty, randomness, and deviations** in data or predictions. Error is not exactly synonymous with variance but they are related.
* Errors arise from:
    * Randomness: unavoidable variability in data, e.g., measurement noise and natural fluctuations
    * Model Imperfections: due to missing information or incorrect model assumptions.
* Statistical models, like regression, often include an error term $\epsilon$ to account for these uncertainties:

$$
Y = f(X) + \epsilon
$$

where $\epsilon$ captures random fluctuations or unknown influences.

While error contributes to variance, they are distinct:

* **Error**: The deviation of an observation from the model's predicted value.
* **Variance**: A statistical measure of how much values deviate from their mean (spread of data).

Errors can be random (causing variability) or systematic (bias), but variance is a quantification of dispersion.

* In regression, we separate variance into **explained variance** (by the model) and **unexplained variance** (error).
* Error variance $\sigma^2$ is modeled to improve predictions and uncertainty estimation.
* For a negative binomial regression model, the **Pearson residual** $r_i$ for observation $i$ is given by:  

$$
r_i = \frac{y_i - \hat{y}_i}{\sqrt{\text{Var}(y_i)}}
$$

where:  
* $y_i$ = observed count  
* $\hat{y}_i$ = predicted mean (expected value under the model)  
* $\text{Var}(y_i)$ = model-estimated variance of $y_i$

* Unlike Poisson regression (where $\text{Var}(y) = \hat{y}$), the **negative binomial** model accounts for **overdispersion** using a dispersion parameter $\theta$, and the variance is:  

$$
\text{Var}(y_i) = \hat{y}_i + \frac{\hat{y}_i^2}{\theta}
$$

This means the variance **grows faster than the mean**, making negative binomial regression suitable when count data has extra variability.

* Pearson residuals can be used for:
    * **Standardized measure** - Large residuals ($|r_i| > 2$) may indicate poor model fit.
    * **Overdispersion check** - If Pearson residuals systematically increase with predicted values, it suggests the model may not fully account for overdispersion.
    * **Model diagnostics** - Residual plots help assess whether assumptions (e.g., correct functional form) hold.

Pearson residuals focus on **variance-adjusted differences** and deviance residuals come from likelihood-based goodness-of-fit measures. They both help diagnose model fit, but deviance residuals tend to emphasise extreme deviations more. Pearson residuals in negative binomial regression are useful for model diagnostics, particularly for checking overdispersion and assessing fit.

### Variance stabilisation

* Variance stabilisation is a statistical transformation technique used to make the **variance of a dataset independent of the mean**.
* In many biological datasets, including scRNA-seq, the variance of gene expression measurements often **increases with the mean expression level**.
    * This heteroskedasticity (non-constant variance) can obscure downstream analyses such as clustering, differential expression testing, or dimensionality reduction.
* The goal of variance stabilisation is to **transform the data** so that the **variance becomes roughly constant across different levels of the mean**, i.e., to achieve homoskedasticity.

Some methods for variance stabilisation:

1. **Logarithmic transformation:**
    * Common when variance increases with the mean.
    * Applied as: `log(x + c)` (where `c` is a pseudocount to handle zeros).
    * Effective when variance increases linearly with the mean.

2. **Square-root transformation:**
    * Applied as: `sqrt(x)`, often used for Poisson-distributed data.
    * Suitable when variance is proportional to the mean.

3. **Variance Stabilising Transformation (VST):**
    * Involves estimating the mean-variance relationship and applying a transformation derived from it.

4. **Regularised methods:**
    * Uses **negative binomial regression** to model and normalise gene expression, accounting for sequencing depth and technical noise.
    * Produces a Pearson residual that approximates homoskedastic behavior.

## Seurat object

Import [raw pbmc3k dataset](pbmc3k.html) from my server.

```{r seurat_obj}
seurat_obj <- readRDS(url("https://davetang.org/file/pbmc3k_seurat.rds", "rb"))
seurat_obj
```

Filter.

```{r pbmc3k}
pbmc3k <- CreateSeuratObject(
  counts = seurat_obj@assays$RNA$counts,
  min.cells = 3,
  min.features = 200,
  project = "pbmc3k"
)
pbmc3k
```

## Seurat workflows

Process with the Seurat 4 workflow.

```{r seurat_wf_v4}
seurat_wf_v4 <- function(seurat_obj, scale_factor = 1e4, num_features = 2000, num_pcs = 30, cluster_res = 0.5, debug_flag = FALSE){
  
  seurat_obj <- NormalizeData(seurat_obj, normalization.method = "LogNormalize", scale.factor = scale_factor, verbose = debug_flag)
  seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = 'vst', nfeatures = num_features, verbose = debug_flag)
  seurat_obj <- ScaleData(seurat_obj, verbose = debug_flag)
  seurat_obj <- RunPCA(seurat_obj, verbose = debug_flag)
  seurat_obj <- RunUMAP(seurat_obj, dims = 1:num_pcs, verbose = debug_flag)
  seurat_obj <- FindNeighbors(seurat_obj, dims = 1:num_pcs, verbose = debug_flag)
  seurat_obj <- FindClusters(seurat_obj, resolution = cluster_res, verbose = debug_flag)
  
  seurat_obj
}

pbmc3k_v4 <- seurat_wf_v4(pbmc3k)
pbmc3k_v4
```

UMAP.

```{r umap_v4}
DimPlot(pbmc3k_v4, reduction = "umap")
```


```{r seurat_wf_v5}
seurat_wf_v5 <- function(seurat_obj, scale_factor = 1e4, num_features = 2000, num_pcs = 30, cluster_res = 0.5, debug_flag = FALSE){
  
  seurat_obj <- SCTransform(seurat_obj, verbose = debug_flag)
  seurat_obj <- RunPCA(seurat_obj, verbose = debug_flag)
  seurat_obj <- RunUMAP(seurat_obj, dims = 1:num_pcs, verbose = debug_flag)
  seurat_obj <- FindNeighbors(seurat_obj, dims = 1:num_pcs, verbose = debug_flag)
  seurat_obj <- FindClusters(seurat_obj, resolution = cluster_res, verbose = debug_flag)
  
  seurat_obj
}

pbmc3k_v5 <- seurat_wf_v5(pbmc3k)
pbmc3k_v5
```

UMAP.

```{r umap_v5}
DimPlot(pbmc3k_v5, reduction = "umap")
```

### Data layer

Version 4 store log normalised data.

```{r pbmc3k_v4_data}
colSums(pbmc3k_v4@assays$RNA$data)[1:6]
```

The data layer is in the SCT assay.

```{r pbmc3k_v5_data}
colSums(pbmc3k_v5@assays$SCT$data)[1:6]
```

### Compare clustering

More granular clustering of version 4's cluster 0 in version 5.

```{r compare_clustering}
stopifnot(all(row.names(pbmc3k_v4@meta.data) == row.names(pbmc3k_v5@meta.data)))

table(
  pbmc3k_v4@meta.data$seurat_clusters,
  pbmc3k_v5@meta.data$seurat_clusters
)
```

## Appendix

More text from the paper [Comparison and evaluation of statistical error models for scRNA-seq](https://link.springer.com/article/10.1186/s13059-021-02584-9).

### Shallow sequencing masks overdispersion in scRNA-seq data

* The rationale behind a Poisson model assumes that homogeneous cells express mRNA molecules for a given gene at a **fixed underlying rate**, and the variation in scRNA-seq results specifically from a **stochastic sampling** of mRNA molecules, for example due to inefficiencies in reverse transcription and PCR, combined with incomplete molecular sampling during DNA sequencing
* While the Poisson distribution is well suited to capture variation driven by stochastic technical loss and sampling noise, it cannot capture other sources of biological heterogeneity between cells that are not driven by changes in cell state, for example, intrinsic variation caused by stochastic transcriptional bursts.
    * These fluctuations would cause scRNA-seq data to deviate from Poisson statistics, exhibiting overdispersion.
* To assess whether scRNA-seq datasets follow the Poisson distribution, the authors performed a goodness-of-fit test, independently modeling the observed counts for each gene to be Poisson distributed, while accounting for differences in sequencing depth between individual cells.
* In each of the 59 datasets analysed, genes exhibiting Poisson variation were overwhelmingly lowly expressed compared to genes that were overdispersed.
    * Moreover, when comparing results for cell-line datasets where we expect low levels of variation in cell state, we found that the global fraction of genes deviating from a Poisson distribution was correlated with the average sequencing depth of the dataset.
* The results suggest that scRNA-seq datasets commonly exhibit biological variation that exceeds Poisson sampling, but that the statistical power to detect these fluctuations requires sufficient sequencing depth.
* After downsampling, only 0.5% genes failed the Poisson goodness-of-fit test, demonstrating that reducing cellular sequencing depth can artificially create the appearance of Poisson variation.
* **The authors conclude that the Poisson error model may represent an acceptable approximation for scRNA-seq datasets with shallow sequencing, but as the sensitivity of molecular profiling continues to increase, error models that allow for overdispersion are required for scRNA-seq analysis**.

### The level of overdispersion varies substantially across datasets

* Recent work suggested that a negative binomial model with a fixed parameterisation (for example, inverse overdispersion parameter $\theta$=100) could be applied to all scRNA-seq datasets to achieve effective variance stabilisation.
* To explore whether a single value of $\theta$ could be applied to diverse scRNA-seq datasets, we first independently fit $\theta$ estimates for each gene in each dataset using a GLM with negative binomial errors (NB GLM), using library size as an offset to account for variation in cellular sequencing depth.
* Substantial differences were observed in the magnitude of the estimated $\theta$ across different datasets, though replicate datasets from the same study yielded concordant results.
    * Consistent with previous results $\theta$ values for each dataset varied across different biological systems, technologies, and sequencing depths.
* To consider different methods for NB parameterisation, we first tested the ability for a single value of $\theta$ to perform effective variance stabilization across a range of datasets.
* Processed 59 datasets using an NB GLM after fixing $\theta$ to a single value for all genes in the dataset (for example, $\theta$=100).
    * Found that no single value of $\theta$ could achieve effective variance stabilisation across all datasets.
* Concluded that fixing a single value of $\theta$ may achieve effective performance in certain cases, but is unlikely to generalise across the diversity of systems and technologies represented by scRNA-seq data.
