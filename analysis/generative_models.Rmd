---
title: "Generative models"
date: "`r Sys.Date()`"
output:
  workflowr::wflow_html:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Discrete example

If we know the rules (parameters) of a mechanism, then even if the outcomes are random, we can generate probabilities of any event by using computations and standard probability laws.

Consider that mutations along the genome of Human Immunodeficiency Virus (HIV) occur at random with a rate of $5 \times 10^{-4}$ per nucleotide per replication cycle. This means that after one cycle, the number of mutations in a genome of about $10^4$ = 10,000 nucleotides will follow a [Poisson distribution](poisson.html) with rate 5.

This **probability model** predicts that the number of mutations over one replication cycle will be close to 5 and that the variability of this estimate is $\sqrt{5}$ (the standard error). We now have baseline reference values for both the number of mutations we expect to see in a typical HIV strain and its variability.

If we want to know how often 3 mutations could occur under the Poisson(5) model, we can use the `dpois()` function to generate the probability of seeing x = 3 events, taking the value of the _rate parameter_ of the Poisson distribution, called lambda ($\lambda$), to be 5.

```{r poisson_lambda_5}
dpois(x = 3, lambda = 5)
```

The output above says that the chance of seeing exactly three events is around 0.14 or about 1 in 7.

Probabilities of a range of values.

```{r dpois_0_to_12}
dpois(x = 0:12, lambda = 5) |>
  barplot(names.arg = 0:12, col = 2)
```

Mathematical theory tells us that the Poisson probability of seeing $x$ is given by:

$$
p = \frac{e^{-\lambda} \lambda^x}{x!}
$$

```{r my_dpois}
my_dpois <- function(x, lambda){
  e <- exp(1)
  ((e^-lambda)*(lambda^x))/factorial(x)
}

my_dpois(3, 5)
dpois(3, 5)
```

The Poisson distribution is a good model for rare events such as mutations. Other useful probability models for discrete events are the Bernoulli, binomial, and multinomial distributions.

### Using discrete probability models

A point mutation can either occur or not; it is a binary event. The two possible outcomes (yes, no) are called the **levels** of the categorical variable. However, not all events are binary such as the genotypes in a diploid organism, which can take three levels: `AA`, `Aa`, and `aa`.

Sometimes the number of levels in a categorical variable is very large; examples include the number of different types of bacteria in a biological sample (hundreds or thousands) and the number of codons formed of three nucleotides (64 levels).

Tossing a coin has two possible outcomes and this simple experiment is called a Bernoulli trial; this is modeled using a so-called Bernoulli random variable. Bernoulli trials can be used to build more complex models.

We can use the `rbinom()` function (`r` for random and `binom` for binomial) to generate some random events that follow a binomial distribution. Below we simulate a sequence of 15 fair coin tosses. For `rbinom()` we have specified 15 trials (`n = 15`), where each individual trial consists of just one single toss (`size = 1`), and the probability of success is 50/50 (`prob = 0.5`).

```{r rbinom_15_coin_toss}
set.seed(1984)
rbinom(n = 15, size = 1, prob = 0.5)
```

Success and failure can have unequal probabilities in a Bernoulli trial, as long as the probabilities sum to one, i.e., complementary events. To simulate 12 trials with unequal probabilities, we just use a different `prob`. The `1`'s indicate success and `0`'s failure.

```{r rbinom_12_unequal}
set.seed(1984)
rbinom(n = 12, size = 1, prob = 2/3)
```

### Binomial success counts

If we only care about successes, then the order doesn't matter and we can just sum the `1`'s. We can get just the successes by setting `n = 1` and `size` to the number of trials. The number of successes below is close to the specified probability.

```{r rbinom_successes}
set.seed(1984)
rbinom(n = 1, size = 100, prob = 2/3)
```

When there are only two possible outcomes, such as heads or tails, we only need to specify the probability, $p$, of "success" since the probability of "failure" is $1 - p$.

The number of successes in 15 Bernoulli trials with a probability of success of 0.3 is called a **binomial** random variable or a random variable that follows the $B$(15,0.3) distribution. If we replicate trial 100 times, we will see that the most frequent value is 4.

```{r rbinom_replicate}
set.seed(1984)
replicate(
  n = 100,
  rbinom(n = 1, prob = 0.3, size = 15)
) |>
  table()
```

The complete **probability mass distribution** is outputted using the `dbinom()` function:

```{r plot_dbinom}
dbinom(0:15, prob = 0.3, size = 15) |>
  barplot(names.arg = 0:15, col = 2)
```

The number of trials is the number we input to R as `size` and is often written $n$, while the probability of success is $p$. Mathematical theory tells us that for $X$ distributed as a binomial distribution with parameters $(n,p)$, written $X \sim B(n,p)$, the probability of seeing $X = k$ successes is

$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
$$

```{r my_dbinom}
my_dbinom <- function(k, n, p){
  choose(n, k) * p^k * (1-p)^(n-k)
}

my_dbinom(4, 15, 0.3)
dbinom(x = 4, size = 15, prob = 0.3)
```

### Epitope detection

When testing certain pharmaceutical compounds, it is important to detect proteins that provoke an allergic reaction. The molecular sites that are responsible for such reactions are called **epitopes**:

> A specific portion of a macromolecular antigen to which an antibody binds. In the case of a protein antigen recognised by a T cell, the epitope or determinant is the peptide portion or site that binds to a major histocompatibility complex (MHC) molecule for recognition by the T-cell receptor (TCR)

An [antibody](antibody.html) is a type of protein made by certain white blood cells in response to a foreign substance in the body, which is called an antigen. An antibody binds (with more or less specificity) to its antigen. The purpose of the binding is to help destroy the antigen.

Antibodies can work in several ways, depending on the nature of the antigen. Some antibodies destroy antigens directly while others help recruit white blood cells to destroy the antigen. An epitope, also known as antigenic determinant, is the part of an antigen that is recognised by the immune system, specifically by antibodies, B cells or T cells.

ELISA assays are used to detect specific epitopes at different positions along a protein. Suppose the following facts hold for an ELISA assay:

* The baseline noise level per position, or more precisely the false positive rate, is 1%. This is the probability of declaring a hit - we think we have an epitope - when there is none. We write this as $P$(declare epitope | no epitope).
* The protein is tested at 100 different positions, supposed to be independent.

Below is data for 50 patients tallied at each of the 100 positions. If there are no allergic reactions, the false positive rate of 1% means that for a single patient, each individual position has a probability of 1 in 100 of being a 1. After tallying 50 patients, we expect at any given position the sum of the 50 observed 0/1 variables to have a Poisson distribution with paramater 0.5 (50 * 1/100).

```{r e100}
load("data/e100.RData")
barplot(e100, names.arg = 1:100, col = 2)
```

What are the chances of seeing a value as large as 7, if no epitope is present?

If we look for the probability of seeing a number as big as 7 (or larger) when considering one Poisson(0.5) random variable, the answer can be calculated in closed form as:

$$
P(X \ge 7) = \sum^\infty_{k=7} P(X = k)
$$

This is the same as $1 - P(X \le 6)$ and the probability $P(X \le 6)$ is the so-called cumulative distribution function at 6 and the `ppois()` function is used this calculate this.

```{r ppois}
1 - ppois(6, 0.5)
```

We denote this number by $\epsilon$ and have shown that the probability of seeing a count as large as 7, assuming no epitope reactions, is:

$$
\epsilon = P(X \ge 7) = 1 - P(X \le 6) \approx 10^{-6}
$$

However, the above calculation is not the correct computation.
